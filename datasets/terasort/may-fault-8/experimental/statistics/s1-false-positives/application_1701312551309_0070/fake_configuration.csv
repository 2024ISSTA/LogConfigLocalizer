,name,value,description
0,yarn.resourcemanager.reservation-system.planfollower.time-step,0,<missing>
1,yarn.resourcemanager.scheduler.client.thread-count,50,
2,dfs.qjournal.get-journal-state.timeout.ms,120000,"Timeout in milliseconds when calling getJournalState().
    JournalNodes."
3,ipc.server.purge.interval,15,"Define how often calls are cleaned up in the server.
    The default is 15 minutes. The unit is minutes."
4,mapreduce.shuffle.max.connections,0,"Max allowed connections for the shuffle.  Set to 0 (zero)
               to indicate no limit on the number of connections."
5,dfs.datanode.bp-ready.timeout,20,"The maximum wait time for datanode to be ready before failing the
    received request. Setting this to 0 fails requests right away if the
    datanode is not yet registered with the namenode. This wait time
    reduces initial request failures after datanode restart.
    Support multiple time unit suffix(case insensitive), as described
    in dfs.heartbeat.interval.If no time unit is specified then seconds
    is assumed."
6,dfs.balancer.block-move.timeout,0,"Maximum amount of time in milliseconds for a block to move. If this is set
    greater than 0, Balancer will stop waiting for a block move completion
    after this time. In typical clusters, a 3 to 5 minute timeout is reasonable.
    If timeout happens to a large proportion of block moves, this needs to be
    increased. It could also be that too much work is dispatched and many nodes
    are constantly exceeding the bandwidth limit as a result. In that case,
    other balancer parameters might need to be adjusted.
    It is disabled (0) by default."
7,hadoop.shell.safely.delete.limit.num.files,100,"Used by -safely option of hadoop fs shell -rm command to avoid
      accidental deletion of large directories. When enabled, the -rm command
      requires confirmation if the number of files to be deleted is greater than
      this limit.  The default limit is 100 files. The warning is disabled if
      the limit is 0 or the -safely is not specified in -rm command."
8,dfs.storage.policy.satisfier.work.multiplier.per.iteration,1,"*Note*: Advanced property. Change with caution.
    This determines the total amount of block transfers to begin in
    one iteration, for satisfy the policy. The actual number is obtained by
    multiplying this multiplier with the total number of live nodes in the
    cluster. The result number is the number of blocks to begin transfers
    immediately. This number can be any positive, non-zero integer."
9,mapreduce.reduce.skip.maxgroups,0,"The number of acceptable skip groups surrounding the bad
    group PER bad group in reducer. The number includes the bad group as well.
    To turn the feature of detection/skipping of bad groups off, set the
    value to 0.
    The framework tries to narrow down the skipped range by retrying
    until this threshold is met OR all attempts get exhausted for this task.
    Set the value to Long.MAX_VALUE to indicate that framework need not try to
    narrow down. Whatever groups(depends on application) get skipped are
    acceptable."
