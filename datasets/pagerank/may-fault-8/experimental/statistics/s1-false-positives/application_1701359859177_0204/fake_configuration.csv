,name,value,description
0,dfs.namenode.snapshotdiff.listing.limit,1709988508,"Limit the number of entries generated by getSnapshotDiffReportListing within
    one rpc call to the namenode.If less or equal to zero, at most
    DFS_NAMENODE_SNAPSHOT_DIFF_LISTING_LIMIT_DEFAULT (= 1000) will be sent
    across to the client within one rpc call."
1,yarn.resourcemanager.placement-constraints.algorithm.pool-size,1,
2,dfs.provided.aliasmap.inmemory.batch-size,500,The batch size when iterating over the database backing the aliasmap
3,dfs.datanode.readahead.bytes,4194304,"While reading block files, if the Hadoop native libraries are available,
        the datanode can use the posix_fadvise system call to explicitly
        page data into the operating system buffer cache ahead of the current
        reader's position. This can improve performance especially when
        disks are highly contended.

        This configuration specifies the number of bytes ahead of the current
        read position which the datanode will attempt to read ahead. This
        feature may be disabled by configuring this property to 0.

        If the native libraries are not available, this configuration has no
        effect."
4,mapreduce.jobhistory.datestring.cache.size,200000,"Size of the date string cache. Effects the number of directories
  which will be scanned to find a job."
5,mapreduce.job.cache.limit.max-resources-mb,0,"The maximum size (in MB) a map reduce job is allowed to submit
    for localization via files, libjars, archives, and jobjar command line
    arguments and through the distributed cache. If set to 0 the limit is
    ignored."
6,dfs.namenode.blockreport.max.lock.hold.time,4,The BlockReportProcessingThread max write lock hold time in ms.
7,dfs.qjournal.accept-recovery.timeout.ms,120000,"Quorum timeout in milliseconds during accept phase of
    recovery/synchronization for a specific segment."
8,yarn.resourcemanager.nodemanager-connect-retries,10,
9,mapreduce.jobhistory.move.thread-count,3,The number of threads used to move files.
