,name,value,description
0,hadoop.security.uid.cache.secs,0.7402799,"This is the config controlling the validity of the entries in the cache
        containing the userId to userName and groupId to groupName used by
        NativeIO getFstat()."
1,dfs.namenode.get-blocks.max-qps,20,"The maximum number of getBlocks RPCs data movement utilities can make to
    a NameNode per second. Values less than or equal to 0 disable throttling.
    This affects anything that uses a NameNodeConnector, i.e., the Balancer,
    Mover, and StoragePolicySatisfier."
2,mapreduce.jobhistory.cleaner.interval-ms,86400000,"How often the job history cleaner checks for files to delete,
  in milliseconds. Defaults to 86400000 (one day). Files are only deleted if
  they are older than mapreduce.jobhistory.max-age-ms."
3,dfs.http.client.failover.sleep.base.millis,500,"Specify the base amount of time in milliseconds upon which the
    exponentially increased sleep time between retries or failovers
    is calculated for WebHDFS client."
4,hadoop.security.crypto.buffer.size,8192,The buffer size used by CryptoInputStream and CryptoOutputStream.
5,yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms,10,
6,yarn.federation.cache-ttl.secs,300,
7,nfs.wtmax,1048576,"This is the maximum size in bytes of a WRITE request
    supported by the NFS gateway. If you change this, make sure you
    also update the nfs mount's wsize(add wsize= # of bytes to the 
    mount directive)."
8,dfs.datanode.slowpeer.low.threshold.ms,5,Threshold in milliseconds below which a DataNode is definitely not slow.
9,mapreduce.am.max-attempts,2,"The maximum number of application attempts. It is a
  application-specific setting. It should not be larger than the global number
  set by resourcemanager. Otherwise, it will be override. The default number is
  set to 2, to allow at least one retry for AM."
