,name,value,description
0,io.bytes.per.checksum,,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,mapreduce.job.speculative.retry-after-speculate,15000,"The waiting time(ms) to do next round of speculation
  if there are tasks speculated in this round."
2,fs.trash.checkpoint.interval,0,"Number of minutes between trash checkpoints.
  Should be smaller or equal to fs.trash.interval. If zero,
  the value is set to the value of fs.trash.interval.
  Every time the checkpointer runs it creates a new checkpoint
  out of current and removes checkpoints created more than
  fs.trash.interval minutes ago."
3,dfs.client.write.byte-array-manager.count-threshold,128,"The count threshold for each array length so that a manager is created only after the
    allocation count exceeds the threshold. In other words, the particular array length
    is not managed until the allocation count exceeds the threshold."
4,dfs.namenode.fs-limits.min-block-size,1048576,"Minimum block size in bytes, enforced by the Namenode at create
      time. This prevents the accidental creation of files with tiny block
      sizes (and thus many blocks), which can degrade performance. Support multiple
      size unit suffix(case insensitive), as described in dfs.blocksize."
5,yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size,10,
6,dfs.datanode.transfer.socket.recv.buffer.size,0,"Socket receive buffer size for DataXceiver (receiving packets from client
    during block writing). This may affect TCP connection throughput.
    If it is set to zero or negative value, no buffer size will be set
    explicitly, thus enable tcp auto-tuning on some system.
    The default value is 0."
7,mapreduce.reduce.skip.maxgroups,0,"The number of acceptable skip groups surrounding the bad
    group PER bad group in reducer. The number includes the bad group as well.
    To turn the feature of detection/skipping of bad groups off, set the
    value to 0.
    The framework tries to narrow down the skipped range by retrying
    until this threshold is met OR all attempts get exhausted for this task.
    Set the value to Long.MAX_VALUE to indicate that framework need not try to
    narrow down. Whatever groups(depends on application) get skipped are
    acceptable."
8,dfs.namenode.blockreport.queue.size,1024,The queue size of BlockReportProcessingThread in BlockManager.
9,dfs.namenode.max.op.size,52428800,Maximum opcode size in bytes.
