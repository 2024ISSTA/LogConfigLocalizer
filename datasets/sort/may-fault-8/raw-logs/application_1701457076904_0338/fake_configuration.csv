,name,value,description
0,io.bytes.per.checksum,,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,dfs.balancer.max-iteration-time,1200000,"Maximum amount of time while an iteration can be run by the Balancer. After
    this time the Balancer will stop the iteration, and reevaluate the work
    needs to be done to Balance the cluster. The default value is 20 minutes."
2,yarn.resourcemanager.leveldb-state-store.compaction-interval-secs,3600,
3,dfs.client.failover.sleep.base.millis,500,"Expert only. The time to wait, in milliseconds, between failover
    attempts increases exponentially as a function of the number of
    attempts made so far, with a random factor of +/- 50%. This option
    specifies the base value used in the failover calculation. The
    first failover will retry immediately. The 2nd failover attempt
    will delay at least dfs.client.failover.sleep.base.millis
    milliseconds. And so on."
4,dfs.ha.fencing.ssh.connect-timeout,30000,"SSH connection timeout, in milliseconds, to use with the builtin
    sshfence fencer."
5,mapreduce.shuffle.max.connections,0,"Max allowed connections for the shuffle.  Set to 0 (zero)
               to indicate no limit on the number of connections."
6,dfs.namenode.fs-limits.max-blocks-per-file,10000,"Maximum number of blocks per file, enforced by the Namenode on
        write. This prevents the creation of extremely large files which can
        degrade performance."
7,dfs.storage.policy.satisfier.queue.limit,1000,"Storage policy satisfier queue size. This queue contains the currently
    scheduled file's inode ID for statisfy the policy.
    Default value is 1000."
8,yarn.app.mapreduce.client.max-retries,3,"The number of client retries to the RM/HS before
    throwing exception. This is a layer above the ipc."
9,dfs.qjournal.http.read.timeout.ms,60000,"Timeout in milliseconds when reading from a HTTP connection from remote
    journals."
