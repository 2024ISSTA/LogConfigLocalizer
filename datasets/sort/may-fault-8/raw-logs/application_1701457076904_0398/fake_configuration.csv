,name,value,description
0,io.bytes.per.checksum,,"The number of bytes per checksum.  Must not be larger than
  io.file.buffer.size."
1,yarn.nodemanager.resource.memory.cgroups.swappiness,0,
2,ha.health-monitor.sleep-after-disconnect.ms,1000,How long to sleep after an unexpected RPC error.
3,dfs.namenode.handler.count,10,"The number of Namenode RPC server threads that listen to
  requests from clients.
  If dfs.namenode.servicerpc-address is not configured then
  Namenode RPC server threads listen to requests from all nodes."
4,yarn.timeline-service.client.internal-timers-ttl-secs,420,
5,dfs.datanode.max.disks.to.report,5,"Number of disks to include in JSON report per operation. We will return
    disks with the highest latency."
6,yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs,3600,
7,dfs.datanode.readahead.bytes,4194304,"While reading block files, if the Hadoop native libraries are available,
        the datanode can use the posix_fadvise system call to explicitly
        page data into the operating system buffer cache ahead of the current
        reader's position. This can improve performance especially when
        disks are highly contended.

        This configuration specifies the number of bytes ahead of the current
        read position which the datanode will attempt to read ahead. This
        feature may be disabled by configuring this property to 0.

        If the native libraries are not available, this configuration has no
        effect."
8,mapreduce.map.maxattempts,4,"Expert: The maximum number of attempts per map task.
  In other words, framework will try to execute a map task these many number
  of times before giving up on it."
9,dfs.content-summary.sleep-microsec,500,"The length of time in microseconds to put the thread to sleep, between reaquiring the locks
    in content summary computation."
