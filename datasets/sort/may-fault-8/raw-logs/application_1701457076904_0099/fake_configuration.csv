,name,value,description
0,dfs.namenode.startup.delay.block.deletion.sec,0,"The delay in seconds at which we will pause the blocks deletion
    after Namenode startup. By default it's disabled.
    In the case a directory has large number of directories and files are
    deleted, suggested delay is one hour to give the administrator enough time
    to notice large number of pending deletion blocks and take corrective
    action."
1,fs.s3a.connection.maximum,96,"Controls the maximum number of simultaneous connections to S3.
    This must be bigger than the value of fs.s3a.threads.max so as to stop
    threads being blocked waiting for new HTTPS connections.
    Why not equal? The AWS SDK transfer manager also uses these connections."
2,dfs.client.read.striped.threadpool.size,18,"The maximum number of threads used for parallel reading
    in striped layout."
3,dfs.client.read.shortcircuit.buffer.size,1048576,Buffer size in bytes for short-circuit local reads.
4,yarn.app.mapreduce.am.job.task.listener.thread-count,30,"The number of threads used to handle RPC calls in the
    MR AppMaster from remote tasks"
5,hadoop.registry.zk.retry.times,5,Zookeeper connection retry count before failing
6,mapreduce.job.cache.limit.max-resources-mb,0,"The maximum size (in MB) a map reduce job is allowed to submit
    for localization via files, libjars, archives, and jobjar command line
    arguments and through the distributed cache. If set to 0 the limit is
    ignored."
7,dfs.namenode.heartbeat.recheck-interval,300000,"This time decides the interval to check for expired datanodes.
    With this value and dfs.heartbeat.interval, the interval of
    deciding the datanode is stale or not is also calculated.
    The unit of this configuration is millisecond."
8,dfs.datanode.restart.replica.expiration,50,"During shutdown for restart, the amount of time in seconds budgeted for
    datanode restart."
9,yarn.resourcemanager.zk-max-znode-size.bytes,1048576,
