,name,value,description
0,dfs.datanode.transfer.socket.recv.buffer.size,1868496599,"Socket receive buffer size for DataXceiver (receiving packets from client
    during block writing). This may affect TCP connection throughput.
    If it is set to zero or negative value, no buffer size will be set
    explicitly, thus enable tcp auto-tuning on some system.
    The default value is 0."
1,mapreduce.job.reducer.unconditional-preempt.delay.sec,300,"The threshold (in seconds) after which an unsatisfied
      mapper request triggers a forced reducer preemption irrespective of the
      anticipated headroom. By default, it is set to 5 mins. Setting it to 0
      leads to immediate reducer preemption. Setting to -1 disables this
      preemption altogether."
2,dfs.client.refresh.read-block-locations.threads,5,"Number of threads to use for refreshing LocatedBlocks of registered
      DFSInputStreams. If a DFSClient opens many DFSInputStreams, increasing
      this may help refresh them all in a timely manner."
3,fs.getspaceused.jitterMillis,60000,fs space usage statistics refresh jitter in msec.
4,yarn.sharedcache.uploader.server.thread-count,50,
5,mapreduce.reduce.shuffle.fetch.retry.timeout-ms,30000,"Timeout value for fetcher to retry to fetch again when some
  non-fatal failure happens because of some events like NM restart."
6,dfs.ha.tail-edits.rolledits.timeout,60,The timeout in seconds of calling rollEdits RPC on Active NN.
7,yarn.dispatcher.print-events-info.threshold,5000,
8,mapreduce.jobhistory.cleaner.interval-ms,86400000,"How often the job history cleaner checks for files to delete,
  in milliseconds. Defaults to 86400000 (one day). Files are only deleted if
  they are older than mapreduce.jobhistory.max-age-ms."
9,dfs.namenode.fs-limits.max-xattr-size,16384,"The maximum combined size of the name and value of an extended attribute
    in bytes. It should be larger than 0, and less than or equal to maximum
    size hard limit which is 32768.
    Support multiple size unit suffix(case insensitive), as described in
    dfs.blocksize."
