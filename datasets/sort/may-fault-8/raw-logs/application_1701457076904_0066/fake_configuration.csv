,name,value,description
0,dfs.journalnode.sync.interval,0,"Time interval, in milliseconds, between two Journal Node syncs.
    This configuration takes effect only if the journalnode sync is enabled
    by setting the configuration parameter dfs.journalnode.enable.sync to true."
1,dfs.mover.movedWinWidth,5400000,"The minimum time interval, in milliseconds, that a block can be
    moved to another location again."
2,yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms,10,
3,dfs.datanode.du.reserved,0,"Reserved space in bytes per volume. Always leave this much space free for non dfs use.
      Specific storage type based reservation is also supported. The property can be followed with
      corresponding storage types ([ssd]/[disk]/[archive]/[ram_disk]) for cluster with heterogeneous storage.
      For example, reserved space for RAM_DISK storage can be configured using property
      'dfs.datanode.du.reserved.ram_disk'. If specific storage type reservation is not configured
      then dfs.datanode.du.reserved will be used. Support multiple size unit suffix(case insensitive),
      as described in dfs.blocksize.
      Note: In case of using tune2fs to set reserved-blocks-percentage, or other filesystem tools,
      then you can possibly run into out of disk errors because hadoop will not check those
      external tool configurations."
4,yarn.app.mapreduce.client-am.ipc.max-retries,3,"The number of client retries to the AM - before reconnecting
    to the RM to fetch Application Status.
    In other words, it is the ipc.client.connect.max.retries to be used during
    reconnecting to the RM and fetching Application Status."
5,dfs.client.write.max-packets-in-flight,80,The maximum number of DFSPackets allowed in flight.
6,dfs.encrypt.data.transfer.cipher.key.bitlength,128,"The key bitlength negotiated by dfsclient and datanode for encryption.
    This value may be set to either 128, 192 or 256."
7,dfs.datanode.ec.reconstruction.threads,8,"Number of threads used by the Datanode for background
    reconstruction work."
8,yarn.app.mapreduce.client.job.max-retries,3,"The number of retries the client will make for getJob and
    dependent calls.
    This is needed for non-HDFS DFS where additional, high level
    retries are required to avoid spurious failures during the getJob call.
    30 is a good value for WASB"
9,dfs.client.write.byte-array-manager.count-threshold,128,"The count threshold for each array length so that a manager is created only after the
    allocation count exceeds the threshold. In other words, the particular array length
    is not managed until the allocation count exceeds the threshold."
