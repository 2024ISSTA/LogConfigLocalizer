,name,value,description
0,dfs.namenode.checkpoint.period,-0.9585963,"The number of seconds between two periodic checkpoints.
    Support multiple time unit suffix(case insensitive), as described
    in dfs.heartbeat.interval.If no time unit is specified then seconds
    is assumed."
1,dfs.client.failover.sleep.base.millis,500,"Expert only. The time to wait, in milliseconds, between failover
    attempts increases exponentially as a function of the number of
    attempts made so far, with a random factor of +/- 50%. This option
    specifies the base value used in the failover calculation. The
    first failover will retry immediately. The 2nd failover attempt
    will delay at least dfs.client.failover.sleep.base.millis
    milliseconds. And so on."
2,dfs.namenode.write-lock-reporting-threshold-ms,5000,"When a write lock is held on the namenode for a long time,
    this will be logged as the lock is released. This sets how long the
    lock must be held for logging to occur."
3,dfs.storage.policy.satisfier.max.outstanding.paths,10000,"Defines the maximum number of paths to satisfy that can be queued up in the
    Satisfier call queue in a period of time. Default value is 10000."
4,yarn.nodemanager.resource-monitor.interval-ms,3000,
5,dfs.client.read.striped.threadpool.size,18,"The maximum number of threads used for parallel reading
    in striped layout."
6,dfs.storage.policy.satisfier.recheck.timeout.millis,60000,"Blocks storage movements monitor re-check interval in milliseconds.
    This check will verify whether any blocks storage movement results arrived from DN
    and also verify if any of file blocks movements not at all reported to DN
    since dfs.storage.policy.satisfier.self.retry.timeout.
    The default value is 1 * 60 * 1000 (1 mins)"
7,mapreduce.job.maxtaskfailures.per.tracker,3,"The number of task-failures on a node manager of a given job
               after which new tasks of that job aren't assigned to it. It
               MUST be less than mapreduce.map.maxattempts and
               mapreduce.reduce.maxattempts otherwise the failed task will
               never be tried on a different node."
8,dfs.provided.aliasmap.inmemory.batch-size,500,The batch size when iterating over the database backing the aliasmap
9,yarn.sharedcache.client-server.thread-count,50,
