,name,value,description
0,dfs.provided.aliasmap.inmemory.batch-size,-0.33829856,The batch size when iterating over the database backing the aliasmap
1,dfs.client.block.write.retries,3,"The number of retries for writing blocks to the data nodes, 
  before we signal failure to the application."
2,hadoop.hdfs.configuration.version,1,version of this configuration file
3,ipc.server.purge.interval,15,"Define how often calls are cleaned up in the server.
    The default is 15 minutes. The unit is minutes."
4,mapreduce.input.fileinputformat.list-status.num-threads,1,"The number of threads to use to list and fetch block locations
  for the specified input paths. Note: multiple threads should not be used
  if a custom non thread-safe path filter is used."
5,dfs.http.client.retry.max.attempts,10,"Specify the max number of retry attempts for WebHDFS client,
    if the difference between retried attempts and failovered attempts is
    larger than the max number of retry attempts, there will be no more
    retries."
6,yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size,1000,
7,dfs.block.scanner.volume.bytes.per.second,1048576,"If this is configured less than or equal to zero, the DataNode's block scanner will be disabled.  If this
        is positive, this is the number of bytes per second that the DataNode's
        block scanner will try to scan from each volume."
8,mapreduce.reduce.cpu.vcores,1,"The number of virtual cores to request from the scheduler for
  each reduce task."
9,yarn.nodemanager.container-log-monitor.interval-ms,60000,
