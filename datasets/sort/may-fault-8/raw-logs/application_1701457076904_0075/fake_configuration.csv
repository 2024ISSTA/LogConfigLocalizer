,name,value,description
0,yarn.resourcemanager.client.thread-count,-540112311,
1,dfs.datanode.slowdisk.low.threshold.ms,20,Threshold in milliseconds below which a disk is definitely not slow.
2,dfs.datanode.balance.max.concurrent.moves,100,"Maximum number of threads for Datanode balancer pending moves.  This
    value is reconfigurable via the ""dfsadmin -reconfig"" command."
3,yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs,86400,
4,dfs.ha.log-roll.period,120,"How often, in seconds, the StandbyNode should ask the active to
    roll edit logs. Since the StandbyNode only reads from finalized
    log segments, the StandbyNode will only be as up-to-date as how
    often the logs are rolled. Note that failover triggers a log roll
    so the StandbyNode will be up to date before it becomes active.
    Support multiple time unit suffix(case insensitive), as described
    in dfs.heartbeat.interval.If no time unit is specified then seconds
    is assumed."
5,mapreduce.job.cache.limit.max-resources-mb,0,"The maximum size (in MB) a map reduce job is allowed to submit
    for localization via files, libjars, archives, and jobjar command line
    arguments and through the distributed cache. If set to 0 the limit is
    ignored."
6,yarn.timeline-service.writer.async.queue.capacity,100,
7,dfs.datanode.directoryscan.throttle.limit.ms.per.sec,1000,"The report compilation threads are limited to only running for
  a given number of milliseconds per second, as configured by the
  property. The limit is taken per thread, not in aggregate, e.g. setting
  a limit of 100ms for 4 compiler threads will result in each thread being
  limited to 100ms, not 25ms.

  Note that the throttle does not interrupt the report compiler threads, so the
  actual running time of the threads per second will typically be somewhat
  higher than the throttle limit, usually by no more than 20%.

  Setting this limit to 1000 disables compiler thread throttling. Only
  values between 1 and 1000 are valid. Setting an invalid value will result
  in the throttle being disabled and an error message being logged. 1000 is
  the default setting."
8,mapreduce.job.reducer.unconditional-preempt.delay.sec,300,"The threshold (in seconds) after which an unsatisfied
      mapper request triggers a forced reducer preemption irrespective of the
      anticipated headroom. By default, it is set to 5 mins. Setting it to 0
      leads to immediate reducer preemption. Setting to -1 disables this
      preemption altogether."
9,hadoop.security.groups.negative-cache.secs,30,"Expiration time for entries in the the negative user-to-group mapping
    caching, in seconds. This is useful when invalid users are retrying
    frequently. It is suggested to set a small value for this expiration, since
    a transient error in group lookup could temporarily lock out a legitimate
    user.

    Set this to zero or negative value to disable negative user-to-group caching."
