,name,value,description
0,yarn.app.mapreduce.client.job.max-retries,0,"The number of retries the client will make for getJob and
    dependent calls.
    This is needed for non-HDFS DFS where additional, high level
    retries are required to avoid spurious failures during the getJob call.
    30 is a good value for WASB"
1,dfs.qjournal.http.read.timeout.ms,60000,"Timeout in milliseconds when reading from a HTTP connection from remote
    journals."
2,yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory,10,
3,dfs.namenode.replication.min,1,Minimal block replication.
4,dfs.datanode.block.id.layout.upgrade.threads,6,"The number of threads to use when creating hard links from
    current to previous blocks during upgrade of a DataNode to block ID-based
    block layout (see HDFS-6482 for details on the layout)."
5,dfs.datanode.ec.reconstruct.write.bandwidthPerSec,0,"Specifies the maximum amount of bandwidth that the EC reconstruction can utilize for writing.
      When the bandwidth value is zero, there is no limit."
6,mapreduce.jobhistory.max-age-ms,604800000,"Job history files older than this many milliseconds will
  be deleted when the history cleaner runs. Defaults to 604800000 (1 week)."
7,yarn.timeline-service.app-collector.linger-period.ms,60000,
8,mapreduce.task.exit.timeout.check-interval-ms,20000,"The interval in milliseconds between which the MR framework
  checks if task attempts stay in finishing state for too long."
9,tfile.fs.output.buffer.size,262144,Buffer size used for FSDataOutputStream in bytes.
