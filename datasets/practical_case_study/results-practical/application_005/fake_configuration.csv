,name,value,description
0,fs.file.impl,org.apache.hadoop.fs.RawLocalFileSystem,
1,yarn.timeline-service.client.fd-retain-secs,300,
2,dfs.namenode.checkpoint.max-retries,3,"The SecondaryNameNode retries failed checkpointing. If the 
  failure occurs while loading fsimage or replaying edits, the number of
  retries is limited by this variable."
3,hadoop.security.kms.client.timeout,60,"Sets value for KMS client connection timeout, and the read timeout
    to KMS servers."
4,dfs.namenode.blocks.per.postponedblocks.rescan,10000,"Number of blocks to rescan for each iteration of
    postponedMisreplicatedBlocks."
5,fs.trash.checkpoint.interval,0,"Number of minutes between trash checkpoints.
  Should be smaller or equal to fs.trash.interval. If zero,
  the value is set to the value of fs.trash.interval.
  Every time the checkpointer runs it creates a new checkpoint
  out of current and removes checkpoints created more than
  fs.trash.interval minutes ago."
6,mapreduce.input.fileinputformat.list-status.num-threads,1,"The number of threads to use to list and fetch block locations
  for the specified input paths. Note: multiple threads should not be used
  if a custom non thread-safe path filter is used."
7,mapreduce.task.userlog.limit.kb,0,The maximum size of user-logs of each task in KB. 0 disables the cap.
8,yarn.timeline-service.client.internal-timers-ttl-secs,420,
9,dfs.storage.policy.satisfier.self.retry.timeout.millis,300000,"If any of file related block movements not at all reported by datanode,
    then after this timeout(in milliseconds), the item will be added back to movement needed list
    at namenode which will be retried for block movements.
    The default value is 5 * 60 * 1000 (5 mins)"
