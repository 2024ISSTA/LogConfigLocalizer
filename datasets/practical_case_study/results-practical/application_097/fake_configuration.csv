,name,value,description
0,fs.default.name,hdfs://localhost:9000 ,
1,hadoop.caller.context.max.size,128,"The maximum bytes a caller context string can have. If the
      passed caller context is longer than this maximum bytes, client will
      truncate it before sending to server. Note that the server may have a
      different maximum size, and will truncate the caller context to the
      maximum size it allows."
2,dfs.client.write.exclude.nodes.cache.expiry.interval.millis,600000,"The maximum period to keep a DN in the excluded nodes list
  at a client. After this period, in milliseconds, the previously excluded node(s) will
  be removed automatically from the cache and will be considered good for block allocations
  again. Useful to lower or raise in situations where you keep a file open for very long
  periods (such as a Write-Ahead-Log (WAL) file) to make the writer tolerant to cluster maintenance
  restarts. Defaults to 10 minutes."
3,dfs.balancer.movedWinWidth,5400000,"Window of time in ms for the HDFS balancer tracking blocks and its
    locations."
4,dfs.namenode.blockreport.queue.size,1024,The queue size of BlockReportProcessingThread in BlockManager.
5,yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep,100,
6,mapreduce.shuffle.max.threads,0,"Max allowed threads for serving shuffle connections. Set to zero
  to indicate the default of 2 times the number of available
  processors (as reported by Runtime.availableProcessors()). Netty is used to
  serve requests, so a thread is not needed for each connection."
7,mapreduce.jobhistory.loadedjobs.cache.size,5,"Size of the loaded job cache.  This property is ignored if
  the property mapreduce.jobhistory.loadedtasks.cache.size is set to a
  positive value."
8,dfs.namenode.top.num.users,10,Number of top users returned by the top tool
9,yarn.nodemanager.logaggregation.threadpool-size-max,100,
